# 大数据面试汇总

#### 先说一些废话
小时候我的数学老师经常会告诫我的一句话就是————知其然知其所以然，所以在以往的工作中我就有总结归纳记录的习惯  
最近因为个人原因最近需要换一份工作，所以再详细的编写一下关于Hive面试内容的博客，希望读者喜欢，有什么错误不对的地方欢迎在评论区指出  

## 未处理过的面试题总结记录  
### 未知公司
1.数仓增量表全量表2.项目数据流向3.*项目hbase的rowkey*4.数仓分层5.断点续传### 深圳优地网络 
1.*sql执行计划*
2.*hive优化*
3.*sql调优*
4.如何查看内存，cpu占用
5.多线程，启动个数如何确定，最多多少
6.java框架
7.数据清洗
8.数据倾斜
### 中软面试流程及问题自我介绍，包括项目介绍和业务介绍
（你在项目中的角色、用到的技术、做的工作）业务的数据量（每天的数据量有多少）*flume的源头数据*你是如何做数据清洗的数仓的整体架构*sqoop的一些参数介绍**hive的窗口函数*建模经验介绍一下### 未知公司
1.业务分析具体讲一讲：什么需求，具体怎么得到2.数据采集 来源+工具+使用中是否遇到问题3.数仓搭建4.*埋点数据缺失怎么处理，埋点数据相关的表示如何设计的*5.*SQL执行错误报警机制*6.SQL题7.项目数据量，日活，漏斗分析注：要体现自己数据分析挖掘能力### sql面试题  
1. 输出每天营业额，按时间倒序，然后侧视图排序1.2.3..4 取出小于等于3的数据。
	这个的结果出来后行专列，生成店铺名name，第一天额度day1，第二天额度day2，第三天额度day3 等四列，然后where条件day3>day2>day1  
2. 找出连续三天及三天以上都有营业额，且营业额都在上涨的店铺  
### 上海博彦科技————技术问题spark：序列化java的io流分类spark的算子分类case class和class的区别option类型泛型斜变逆变函数柯里化

**下次从这里说**
---------------------------------------------隐式函数flink-cdc数仓开发指标编写mysql存储过程flink和spark的区别
### 未知公司
spark 基础 	excutor 
java scala 基础
Java内部类和外部类：
在Java中，可以将一个类定义在另一个类里面或者一个方法里面，这样的类称为内部类
内部类一般来说包括这四种：成员内部类、局部内部类、匿名内部类和静态内部类
静态成员内部类：使用static修饰类；
非静态成员内部类：未用static修饰类，在没有说明是静态成员内部类时，默认成员内部类指的就是非静态成员内部类；
全局变量、静态全局变量、静态局部变量和局部变量的区别：
变量可以分为：全局变量、静态全局变量、静态局部变量和局部变量。
按存储区域分，全局变量、静态全局变量和静态局部变量都存放在内存的静态存储区域，局部变量存放在内存的栈区。
按作用域分，全局变量在整个工程文件内都有效；静态全局变量只在定义它的文件内有效；静态局部变量只在定义它的函数内有效，并且程序仅分配一次内存，函数返回后，该变量不会消失；局部变量在定义它的函数内有效，但是函数返回后失效。
全局变量(外部变量)的说明之前再冠以static 就构成了静态的全局变量。全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。 这两者在存储方式上并无不同。这两者的区别在于非静态全局变量的作用域是整个源程序，当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的。 而静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。由于静态全局变量的作用域局限于一个源文件内，只能为该源文件内的函数公用， 因此可以避免在其它源文件中引起错误。
从以上分析可以看出，把局部变量改变为静态变量后是改变了它的存储方式即改变了它的生存期。把全局变量改变为静态变量后是改变了它的作用域，限制了它的使用范围。
static函数与普通函数作用域不同，只在定义该变量的源文件内有效。只在当前源文件中使用的函数应该说明为内部函数(static)，内部函数应该在当前源文件中说明和定义。对于可在当前源文件以外使用的函数，应该在一个头文件中说明，要使用这些函数的源文件要包含这个头文件。
static全局变量与普通的全局变量有什么区别：static全局变量只初使化一次，防止在其他文件单元中被引用;
static局部变量和普通局部变量有什么区别：static局部变量只被初始化一次，下一次依据上一次结果值；
static函数与普通函数有什么区别：static函数与普通函数作用域不同，只在定义该变量的源文件内有效；
全局变量和静态变量如果没有手工初始化，则由编译器初始化为0。局部变量的值不可知。
重写与重载之间的区别：
方法重载：
1、同一个类中
2、方法名相同，参数列表不同（参数顺序、个数、类型）
3、方法返回值、访问修饰符任意
4、与方法的参数名无关
方法重写：
1、有继承关系的子类中
2、方法名相同，参数列表相同（参数顺序、个数、类型），方法返回值相同
3、访问修饰符，访问范围需要大于等于父类的访问范围
4、与方法的参数名无关
java final关键字：
final关键字可以用来修饰类、方法和变量（包括成员变量和局部变量）
final修饰的类不可被继承，即final类没有子类
final修饰的方法不可被子类重写
final修饰的变量=常量，final变量一旦赋值了就无法改变
当方法中的参数被final修饰，该方法只能读取该参数而无法修改该参数
scala 是否可以多继承
Scala 中的多重继承由特质（trait）实现并遵循线性化规则。 在多重继承中，如果一个特质已经显式扩展了一个类，则混入该特质的类必须是之前特质混入的类的子类。 这意味着当混入一个已扩展了别的类的特质时，他们必须拥有相同的父类。
如何查看Spark日志与排查报错问题
[参考文档](https://blog.csdn.net/qq_33588730/article/details/109353336)
如果你运行在YARN模式，你可以在ResourceManager节点的WEB UI页面选择相关的应用程序，在页面点击表格中Tracking UI列的ApplicationMaster，这时候你可以进入到Spark作业监控的WEB UI界面，这个页面就是你Spark应用程序的proxy界面，
[参考文档](https://www.cnblogs.com/gaopeng527/p/4961604.html)
spark 调优
hive 优化
shell脚本 定义函数调用
shell脚本第一行：#!/bin/bash的含义：
第一行的内容指定了shell脚本解释器的路径，而且这个指定路径只能放在文件的第一行。第一行写错或者不写时，系统会有一个默认的解释器进行解释。
linux 脚本授权,Linux授权命令
chmod +x  目录/文件名
Shell标准输出、标准错误 >/dev/null 2>&1
Spark中Task数量的分析：
Job(作业)：Spark根据行动操作触发提交作业，以行动操作将我们的代码切分为多个Job。
Stage(调度阶段)：每个Job中，又会根据宽依赖将Job划分为多个Stage(包括ShuffleMapStage和ResultStage)。
Task(任务)：真正执行计算的部分。Stage相当于TaskSet，每个Stage内部包含了多个Task，将各个Task下发到各个Executor执行计算。
每个Task的处理逻辑完全一样，不同的是对应处理的数据。即：移动计算而不是移动数据。
Partition(分区)：这个是针对RDD而言的，RDD内部维护了分区列表，表示数据在集群中存放的不同位置。[参考文档](https://www.cnblogs.com/upupfeng/p/12385979.html)
spark 数据清洗有哪些及解决问题
spark 提供的序列化类
Hadoop 序列化 反序列化
RDD持久化
spark算子
HDFS容错机制 [参考文档](https://www.cnblogs.com/zhangyinhua/p/7681146.html)
spark应用 执行时划分单位
spark task 数目由什么决定
spark 懒加载
HDFS写数据过程
Hadoop的组成
### 未知公司
hive 有任务跑的时间比较长，怎么优化 
hive 参数设置 
mapjoin 什么时候走 mapjoin
什么情况下会产生 hive 小文件
小文件的危害
一条 sql 语句，多个字段，如何考虑写尽量提升效率 
hive 日志如何反查哪条 Sql 执行较慢
数仓分层，自己负责哪些模块
写 sql 题：姓名，学利 · ，分数，统计总分前六名
mapreduce 的过程 
hive 查询过程，哪些方法可以提高查询效率
hive 常用的窗口函数 
redis 支持的数据类型
sparkstreaming 怎么保证精准的消费 
java 怎么写事务
### 未知公司
1 、自我介绍 
2 、最近的项目介绍 
3 、项目数据量 
4 、数据流向及用到的技术 
5 、 hive Sql 的优化 
6 、处理后的数据用途 
7 、 Sql 题：找出两表中都有的 id
### 未知公司
1、自我介绍 
2 、项目技术链介绍 
3 、项目数据流 
4 、简单介绍下 kafka 的核心概念及个人理解 
5 、项目数据传输过程中导致的重复数据怎么处理 
6 、 hivesql 查询比较慢，怎么处理 
7 、项目内的 hive 里面的表格数量 
8 、 Spark 的版本，及常用的算子，惰性执行 
9 、 hive 交互查询的组件，查询效率怎样 
10 、大数据集群是什么集群？ CDH吗？ 
11 、 hive 查询组件 impala 了解吗 
12 、 hbase 和 hive 的区别知道吗？ 
		hbase 查询用的多吗，
		用户画像构建是用 hbase 做的吗，
		特征值怎么提取的 
13 、 Spark 和 hive 查询中遇到过什么难点 
14 、 hive 参数调优 
15 、 flink 的 windoWAPi 的分类介绍 
16 、 hive 表格关联方式的 join 分类、用法、应用场景 
17 、 hivesql 的数据去重的方法 
18 、 hive 的窗口函数介绍，窗口函数怎么去重 
19 、 hive 的 dag 了解吗
### 未知公司
scala 的特性
柯里化的优点
偏应用函数 
Scala 的闭包 
Scala 的 object 是什么 
Scala 中的隐式装换 
Scala 的 String 是可变的吗
离线任务有多少个及任务执行时间
数据有多少个指标 
hive 中的行列转换，除了 case when 的其他方法
 hivesql 中常见的函数，窗口函数的区别 Rownumber 、 rank 、 dense rank explode 炸裂函数 
 hive 的内部表和外部表的区别
 内部表和外部表如果删除，元数据是由谁来维护（ metastore ) 
 hive 的元数据理解，他的存储位置及管理者是谁？
 分区和分桶的区别，分桶的原理
 分区可以提高查询效率吗？是不是分区越多越好 
 hive 任务处理过程中遇到的问题 
 spark 的转换算子和行动算子 
 spark 的 Stage 和 task 的划分 
 spark 的宽窄依赖
 ### 未知公司
l 、自我介绍 
2 、项目技术链介绍 
3 、项目数据流 
4 、简单介绍下 kafka 的核心概念及个人理解 
5 、项目数据传输过程中导致的重复数据怎么处理 
6 、 hivesql 查询比较慢，怎么处理 
7 、项目内的 hive 里面的表格数量 
8 、 Spark 的版本，及常用的算子，惰性执行 
9 、 hive 交互查询的组件，查询效率怎样 
10 、大数据集群是什么集群？ CDH 吗？ 
11 、 hive 查询组件 impala 了解吗 
12 、 hbase 和 hive 的区别知道吗？ hbase 查询用的多吗，用户画像构建是用 hbase 做的吗，特征值怎么提取的 
13 、 Spark 和 hive 查询中遇到过什么难点 
14 、 hive 参数调优 
15 、 fhnk 的 windowAPi 的分类介绍 
16 、 hive 表格关联方式的 join 分类、用法、应用场景 
17 、 hivesql 的数据去重的方法 
18 、 hive 的窗口函数介绍，窗口函数怎么去重 
19 、 hive 的 dag 了解吗
### 未知公司
2 ．简单介绍一下你的业务 
3 ．数仓的人员分配 
4 ．你们的主题是根据什么来划分，为什么这么划分 
5 ．你们源数据大概多少张表 
6 ．你们的日志数据到建立事实表的过程中，主要做了什么
 7 ．你们的维度层是怎么建设的 
 8 ．如果在解析日志文件时遇到很多的硬编码，如何使用维度去解决 
 9 ．如果指标出现同义不同名的情况如何解决 
 10 ．阿里的 oneData 体系有了解吗 
 11 ．你们如何保证数据质量的 
 12 ．你日常遇到最多的数据质量问题是什么？ 
 13 ．你们的需求周期一般是多久？拿到需求之后怎么分析 
 14 ．在完成需求的过程中，有没有考虑过数仓的通用性．你们是如何体现的 
 15 ．有做过用户路径模型吗？每条路径的转化率是多少 
 16 ．你在工作中的最大收获是什么，带给你什么样的能力 
 17 ．你们的工作强度怎么样，能接受加班吗？ 
 18 ．如果一周内让你做＋个紧急的需求，你会怎么办？ 
 19 ．你们部门之间是直接进行对接吗？ 
 20 ．有没有反驳过产品提出的需求，如果不合理怎么办？ 
 21 ．你在实时开发的过程中遇到什么问题．如何解决的 
 22 ．你们的实时模型是如何进行优化的，怎么评估它是否是一个优质的模型 
 23 ．你们有有过 clickhouse 做 join 吗，如何保证秒级延迟
 24   flink的cep了解么？怎么使用的 
 25 ．你们的任务监控有做过吗，主要监控什么 
 26 ．你们如何保证数据的准确性
### 未知公司
1 ，简单介绍一下你的业务 
2 能说说你们数据的零点漂移是如何解决的吗 
3 能结合业务说说你们的数仓怎么搭建的吗 
4 ，你们之前使用 spork 做实时，后来为什么使用 flink 了 
5 . flink 的水位线了解吗，可以具体讲讲吗 
6 ．两道 sQI 题
### 未知公司
1 ，你主要负责哪些模块 
2 ．如果给你一个需求，你会如何进行分析 
3 能结合业务说说你们的数仓怎么搭建的吗 
4 ．你们的 OLAp 引擎主要用的什么，为什么这样选型 
5 能聊聊端到端的一致性和精准一次消费吗 
6 ．你们 flink 主要使用api 开发还是 aql开发 
7 ：能讲讲双流 join 是如何实现的吗 
8 ．实时开发过程中有遇到什么问题吗？是如何解决的